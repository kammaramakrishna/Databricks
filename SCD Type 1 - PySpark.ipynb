{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c7e6ba4-af24-4433-b5be-b9a868d4ae35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, current_timestamp,coalesce\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, TimestampType\n",
    "from datetime import datetime\n",
    "\n",
    "# Define schema for the source DataFrame\n",
    "source_schema = StructType([\n",
    "    StructField(\"Emp_ID\", IntegerType(), False),\n",
    "    StructField(\"First_Name\", StringType(), False),\n",
    "    StructField(\"Last_Name\", StringType(), False),\n",
    "    StructField(\"Salary\", FloatType(), False),\n",
    "    StructField(\"Nationality\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False)\n",
    "])\n",
    "\n",
    "# Define initial data with datetime objects\n",
    "initial_data = [\n",
    "    (1, 'Scott', 'Tiger', 1000.0, 'India', datetime(2023, 1, 1, 0, 0, 0)),\n",
    "    (2, 'John', 'Clair', 2000.0, 'UK', datetime(2023, 1, 1, 0, 0, 0))\n",
    "]\n",
    "employee_source = spark.createDataFrame(initial_data, schema=source_schema)\n",
    "\n",
    "# Convert the timestamp field from string to TimestampType\n",
    "employee_source = employee_source.withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType()))\n",
    "\n",
    "\n",
    "# Define schema for the target DataFrame\n",
    "target_schema = StructType([\n",
    "    StructField(\"Emp_ID\", IntegerType(), False),\n",
    "    StructField(\"First_Name\", StringType(), False),\n",
    "    StructField(\"Last_Name\", StringType(), False),\n",
    "    StructField(\"Salary\", FloatType(), False),\n",
    "    StructField(\"Nationality\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Create an empty target DataFrame\n",
    "employee_target = spark.createDataFrame([], schema=target_schema)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6145e804-9fe2-4a29-bb27-5867eb9d1168",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+-------+-----------+\n|Emp_ID|First_Name|Last_Name| Salary|Nationality|\n+------+----------+---------+-------+-----------+\n|     1|     Scott|    Tiger|1000.13|        USA|\n|     2|      John|    Clair| 2000.0|         UK|\n+------+----------+---------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate the source DataFrame based on the latest timestamp\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "windowSpec = Window.partitionBy(\"Emp_ID\").orderBy(col(\"timestamp\").desc())\n",
    "deduped_employee_source = employee_source.withColumn(\"row_num\", row_number().over(windowSpec)).filter(col(\"row_num\") == 1).drop(\"row_num\")\n",
    "\n",
    "# Merge operation: update existing records and insert new ones\n",
    "# Join the target with the deduped source DataFrame\n",
    "merged_df = employee_target.alias('target').join(\n",
    "    deduped_employee_source.alias('source'),\n",
    "    on='Emp_ID',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Create updated DataFrame\n",
    "updated_df = merged_df.select(\n",
    "    coalesce(col('source.Emp_ID'), col('target.Emp_ID')).alias('Emp_ID'),\n",
    "    coalesce(col('source.First_Name'), col('target.First_Name')).alias('First_Name'),\n",
    "    coalesce(col('source.Last_Name'), col('target.Last_Name')).alias('Last_Name'),\n",
    "    coalesce(col('source.Salary'), col('target.Salary')).alias('Salary'),\n",
    "    coalesce(col('source.Nationality'), col('target.Nationality')).alias('Nationality')\n",
    ")\n",
    "\n",
    "# Show the updated target DataFrame\n",
    "updated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c80093d-1303-418d-a603-51f4627870b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Insert new data into the source DataFrame\n",
    "new_data = [\n",
    "    (1, 'Scott', 'Tiger', 1000.13, 'USA', datetime(2023, 1, 2, 0, 0, 0))\n",
    "]\n",
    "new_employee_source = spark.createDataFrame(new_data, schema=source_schema)\n",
    "\n",
    "# Union new data with existing source data\n",
    "employee_source = employee_source.union(new_employee_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd1090a-be9f-4fd6-8d2e-387fcc8dd00a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.rm(\"dbfs:/user/hive/warehouse/employee_target\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419e9925-390a-43b1-937d-94ccb317c876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "\u001B[0;32m<command-1101136203510778>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     11\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 12\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     14\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m<command-1101136203510778>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gQ3JlYXRlIHRoZSB0YXJnZXQgdGFibGUgaWYgaXQgZG9lcyBub3QgZXhpc3QKQ1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgZW1wbG95ZWVfdGFyZ2V0ICgKICAgIEVtcF9JRCBJTlQsCiAgICBGaXJzdF9OYW1lIFNUUklORywKICAgIExhc3RfTmFtZSBTVFJJTkcsCiAgICBTYWxhcnkgRkxPQVQsCiAgICBOYXRpb25hbGl0eSBTVFJJTkcsCiAgICBzdGFydF9kYXRlIERBVEUsCiAgICBlbmRfZGF0ZSBEQVRFLAogICAgY3VycmVudF9mbGFnIEJPT0xFQU4KKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gQ3JlYXRlIGEgQ1RFIHRvIGdldCB0aGUgbGF0ZXN0IHJlY29yZHMgZnJvbSB0aGUgc291cmNlIHRhYmxlCldJVEggbGF0ZXN0X2VtcGxveWVlX3JlY29yZHMgQVMgKAogICAgU0VMRUNUIEVtcF9JRCwgRmlyc3RfTmFtZSwgTGFzdF9OYW1lLCBTYWxhcnksIE5hdGlvbmFsaXR5LCB0aW1lc3RhbXAKICAgIEZST00gKAogICAgICAgIFNFTEVDVCAKICAgICAgICAgICAgKiwKICAgICAgICAgICAgUk9XX05VTUJFUigpIE9WRVIgKFBBUlRJVElPTiBCWSBFbXBfSUQgT1JERVIgQlkgdGltZXN0YW1wIERFU0MpIGFzIHJuCiAgICAgICAgRlJPTSBlbXBsb3llZV9zb3VyY2UKICAgICkgc3VicXVlcnkKICAgIFdIRVJFIHJuID0gMQopCgotLSBQZXJmb3JtIHRoZSBTQ0QgVHlwZSAyIE1FUkdFIG9wZXJhdGlvbgpNRVJHRSBJTlRPIGVtcGxveWVlX3RhcmdldCBBUyB0YXJnZXQKVVNJTkcgKAogICAgU0VMRUNUIAogICAgICAgIEVtcF9JRCwgCiAgICAgICAgRmlyc3RfTmFtZSwgCiAgICAgICAgTGFzdF9OYW1lLCAKICAgICAgICBTYWxhcnksIAogICAgICAgIE5hdGlvbmFsaXR5LCAKICAgICAgICB0aW1lc3RhbXAKICAgIEZST00gbGF0ZXN0X2VtcGxveWVlX3JlY29yZHMKKSBBUyBzb3VyY2UKT04gdGFyZ2V0LkVtcF9JRCA9IHNvdXJjZS5FbXBfSUQgQU5EIHRhcmdldC5jdXJyZW50X2ZsYWcgPSBUUlVFCldIRU4gTUFUQ0hFRCAKICAgIEFORCAoCiAgICAgICAgdGFyZ2V0LkZpcnN0X05hbWUgIT0gc291cmNlLkZpcnN0X05hbWUgT1IgCiAgICAgICAgdGFyZ2V0Lkxhc3RfTmFtZSAhPSBzb3VyY2UuTGFzdF9OYW1lIE9SIAogICAgICAgIHRhcmdldC5TYWxhcnkgIT0gc291cmNlLlNhbGFyeSBPUiAKICAgICAgICB0YXJnZXQuTmF0aW9uYWxpdHkgIT0gc291cmNlLk5hdGlvbmFsaXR5CiAgICApClRIRU4KICAgIFVQREFURSBTRVQKICAgICAgICB0YXJnZXQuY3VycmVudF9mbGFnID0gRkFMU0UsCiAgICAgICAgdGFyZ2V0LmVuZF9kYXRlID0gc291cmNlLnRpbWVzdGFtcApXSEVOIE5PVCBNQVRDSEVEIFRIRU4KICAgIElOU0VSVCAoCiAgICAgICAgRW1wX0lELAogICAgICAgIEZpcnN0X05hbWUsCiAgICAgICAgTGFzdF9OYW1lLAogICAgICAgIFNhbGFyeSwKICAgICAgICBOYXRpb25hbGl0eSwKICAgICAgICBzdGFydF9kYXRlLAogICAgICAgIGVuZF9kYXRlLAogICAgICAgIGN1cnJlbnRfZmxhZwogICAgKQogICAgVkFMVUVTICgKICAgICAgICBzb3VyY2UuRW1wX0lELAogICAgICAgIHNvdXJjZS5GaXJzdF9OYW1lLAogICAgICAgIHNvdXJjZS5MYXN0X05hbWUsCiAgICAgICAgc291cmNlLlNhbGFyeSwKICAgICAgICBzb3VyY2UuTmF0aW9uYWxpdHksCiAgICAgICAgc291cmNlLnRpbWVzdGFtcCwKICAgICAgICBOVUxMLAogICAgICAgIFRSVUUKICAgICk=\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gSW5zZXJ0IG5ldyByZWNvcmRzIGZvciB0aGUgdXBkYXRlZCBlbnRyaWVzCklOU0VSVCBJTlRPIGVtcGxveWVlX3RhcmdldCAoRW1wX0lELCBGaXJzdF9OYW1lLCBMYXN0X05hbWUsIFNhbGFyeSwgTmF0aW9uYWxpdHksIHN0YXJ0X2RhdGUsIGVuZF9kYXRlLCBjdXJyZW50X2ZsYWcpClNFTEVDVCAKICAgIHNvdXJjZS5FbXBfSUQsIAogICAgc291cmNlLkZpcnN0X05hbWUsIAogICAgc291cmNlLkxhc3RfTmFtZSwgCiAgICBzb3VyY2UuU2FsYXJ5LCAKICAgIHNvdXJjZS5OYXRpb25hbGl0eSwgCiAgICBzb3VyY2UudGltZXN0YW1wLAogICAgTlVMTCwKICAgIFRSVUUKRlJPTSBsYXRlc3RfZW1wbG95ZWVfcmVjb3JkcyBzb3VyY2UKSk9JTiBlbXBsb3llZV90YXJnZXQgdGFyZ2V0Ck9OIHRhcmdldC5FbXBfSUQgPSBzb3VyY2UuRW1wX0lEIEFORCB0YXJnZXQuZW5kX2RhdGUgPSBzb3VyY2UudGltZXN0YW1wCldIRVJFIHRhcmdldC5GaXJzdF9OYW1lICE9IHNvdXJjZS5GaXJzdF9OYW1lIAogICAgT1IgdGFyZ2V0Lkxhc3RfTmFtZSAhPSBzb3VyY2UuTGFzdF9OYW1lIAogICAgT1IgdGFyZ2V0LlNhbGFyeSAhPSBzb3VyY2UuU2FsYXJ5IAogICAgT1IgdGFyZ2V0Lk5hdGlvbmFsaXR5ICE9IHNvdXJjZS5OYXRpb25hbGl0eQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gU2VsZWN0IGRhdGEgZnJvbSB0aGUgdGFyZ2V0IHRhYmxlIHRvIHZlcmlmeSBjaGFuZ2VzClNFTEVDVCAqIEZST00gZW1wbG95ZWVfdGFyZ2V0IE9SREVSIEJZIEVtcF9JRCwgc3RhcnRfZGF0ZQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n",
       "\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n",
       "\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: latest_employee_records; line 12 pos 5;\n",
       "'InsertIntoStatement 'UnresolvedRelation [employee_target], [], false, [Emp_ID, First_Name, Last_Name, Salary, Nationality, start_date, end_date, current_flag], false, false\n",
       "+- 'Project ['source.Emp_ID, 'source.First_Name, 'source.Last_Name, 'source.Salary, 'source.Nationality, 'source.timestamp, unresolvedalias(null, None), unresolvedalias(true, None)]\n",
       "   +- 'Filter ((NOT ('target.First_Name = 'source.First_Name) OR NOT ('target.Last_Name = 'source.Last_Name)) OR (NOT ('target.Salary = 'source.Salary) OR NOT ('target.Nationality = 'source.Nationality)))\n",
       "      +- 'Join Inner, (('target.Emp_ID = 'source.Emp_ID) AND ('target.end_date = 'source.timestamp))\n",
       "         :- 'SubqueryAlias source\n",
       "         :  +- 'UnresolvedRelation [latest_employee_records], [], false\n",
       "         +- SubqueryAlias target\n",
       "            +- SubqueryAlias spark_catalog.default.employee_target\n",
       "               +- Relation spark_catalog.default.employee_target[Emp_ID#6807,First_Name#6808,Last_Name#6809,Salary#6810,Nationality#6811,start_date#6812,end_date#6813,current_flag#6814] parquet\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-1101136203510778>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m<command-1101136203510778>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gQ3JlYXRlIHRoZSB0YXJnZXQgdGFibGUgaWYgaXQgZG9lcyBub3QgZXhpc3QKQ1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgZW1wbG95ZWVfdGFyZ2V0ICgKICAgIEVtcF9JRCBJTlQsCiAgICBGaXJzdF9OYW1lIFNUUklORywKICAgIExhc3RfTmFtZSBTVFJJTkcsCiAgICBTYWxhcnkgRkxPQVQsCiAgICBOYXRpb25hbGl0eSBTVFJJTkcsCiAgICBzdGFydF9kYXRlIERBVEUsCiAgICBlbmRfZGF0ZSBEQVRFLAogICAgY3VycmVudF9mbGFnIEJPT0xFQU4KKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gQ3JlYXRlIGEgQ1RFIHRvIGdldCB0aGUgbGF0ZXN0IHJlY29yZHMgZnJvbSB0aGUgc291cmNlIHRhYmxlCldJVEggbGF0ZXN0X2VtcGxveWVlX3JlY29yZHMgQVMgKAogICAgU0VMRUNUIEVtcF9JRCwgRmlyc3RfTmFtZSwgTGFzdF9OYW1lLCBTYWxhcnksIE5hdGlvbmFsaXR5LCB0aW1lc3RhbXAKICAgIEZST00gKAogICAgICAgIFNFTEVDVCAKICAgICAgICAgICAgKiwKICAgICAgICAgICAgUk9XX05VTUJFUigpIE9WRVIgKFBBUlRJVElPTiBCWSBFbXBfSUQgT1JERVIgQlkgdGltZXN0YW1wIERFU0MpIGFzIHJuCiAgICAgICAgRlJPTSBlbXBsb3llZV9zb3VyY2UKICAgICkgc3VicXVlcnkKICAgIFdIRVJFIHJuID0gMQopCgotLSBQZXJmb3JtIHRoZSBTQ0QgVHlwZSAyIE1FUkdFIG9wZXJhdGlvbgpNRVJHRSBJTlRPIGVtcGxveWVlX3RhcmdldCBBUyB0YXJnZXQKVVNJTkcgKAogICAgU0VMRUNUIAogICAgICAgIEVtcF9JRCwgCiAgICAgICAgRmlyc3RfTmFtZSwgCiAgICAgICAgTGFzdF9OYW1lLCAKICAgICAgICBTYWxhcnksIAogICAgICAgIE5hdGlvbmFsaXR5LCAKICAgICAgICB0aW1lc3RhbXAKICAgIEZST00gbGF0ZXN0X2VtcGxveWVlX3JlY29yZHMKKSBBUyBzb3VyY2UKT04gdGFyZ2V0LkVtcF9JRCA9IHNvdXJjZS5FbXBfSUQgQU5EIHRhcmdldC5jdXJyZW50X2ZsYWcgPSBUUlVFCldIRU4gTUFUQ0hFRCAKICAgIEFORCAoCiAgICAgICAgdGFyZ2V0LkZpcnN0X05hbWUgIT0gc291cmNlLkZpcnN0X05hbWUgT1IgCiAgICAgICAgdGFyZ2V0Lkxhc3RfTmFtZSAhPSBzb3VyY2UuTGFzdF9OYW1lIE9SIAogICAgICAgIHRhcmdldC5TYWxhcnkgIT0gc291cmNlLlNhbGFyeSBPUiAKICAgICAgICB0YXJnZXQuTmF0aW9uYWxpdHkgIT0gc291cmNlLk5hdGlvbmFsaXR5CiAgICApClRIRU4KICAgIFVQREFURSBTRVQKICAgICAgICB0YXJnZXQuY3VycmVudF9mbGFnID0gRkFMU0UsCiAgICAgICAgdGFyZ2V0LmVuZF9kYXRlID0gc291cmNlLnRpbWVzdGFtcApXSEVOIE5PVCBNQVRDSEVEIFRIRU4KICAgIElOU0VSVCAoCiAgICAgICAgRW1wX0lELAogICAgICAgIEZpcnN0X05hbWUsCiAgICAgICAgTGFzdF9OYW1lLAogICAgICAgIFNhbGFyeSwKICAgICAgICBOYXRpb25hbGl0eSwKICAgICAgICBzdGFydF9kYXRlLAogICAgICAgIGVuZF9kYXRlLAogICAgICAgIGN1cnJlbnRfZmxhZwogICAgKQogICAgVkFMVUVTICgKICAgICAgICBzb3VyY2UuRW1wX0lELAogICAgICAgIHNvdXJjZS5GaXJzdF9OYW1lLAogICAgICAgIHNvdXJjZS5MYXN0X05hbWUsCiAgICAgICAgc291cmNlLlNhbGFyeSwKICAgICAgICBzb3VyY2UuTmF0aW9uYWxpdHksCiAgICAgICAgc291cmNlLnRpbWVzdGFtcCwKICAgICAgICBOVUxMLAogICAgICAgIFRSVUUKICAgICk=\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gSW5zZXJ0IG5ldyByZWNvcmRzIGZvciB0aGUgdXBkYXRlZCBlbnRyaWVzCklOU0VSVCBJTlRPIGVtcGxveWVlX3RhcmdldCAoRW1wX0lELCBGaXJzdF9OYW1lLCBMYXN0X05hbWUsIFNhbGFyeSwgTmF0aW9uYWxpdHksIHN0YXJ0X2RhdGUsIGVuZF9kYXRlLCBjdXJyZW50X2ZsYWcpClNFTEVDVCAKICAgIHNvdXJjZS5FbXBfSUQsIAogICAgc291cmNlLkZpcnN0X05hbWUsIAogICAgc291cmNlLkxhc3RfTmFtZSwgCiAgICBzb3VyY2UuU2FsYXJ5LCAKICAgIHNvdXJjZS5OYXRpb25hbGl0eSwgCiAgICBzb3VyY2UudGltZXN0YW1wLAogICAgTlVMTCwKICAgIFRSVUUKRlJPTSBsYXRlc3RfZW1wbG95ZWVfcmVjb3JkcyBzb3VyY2UKSk9JTiBlbXBsb3llZV90YXJnZXQgdGFyZ2V0Ck9OIHRhcmdldC5FbXBfSUQgPSBzb3VyY2UuRW1wX0lEIEFORCB0YXJnZXQuZW5kX2RhdGUgPSBzb3VyY2UudGltZXN0YW1wCldIRVJFIHRhcmdldC5GaXJzdF9OYW1lICE9IHNvdXJjZS5GaXJzdF9OYW1lIAogICAgT1IgdGFyZ2V0Lkxhc3RfTmFtZSAhPSBzb3VyY2UuTGFzdF9OYW1lIAogICAgT1IgdGFyZ2V0LlNhbGFyeSAhPSBzb3VyY2UuU2FsYXJ5IAogICAgT1IgdGFyZ2V0Lk5hdGlvbmFsaXR5ICE9IHNvdXJjZS5OYXRpb25hbGl0eQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LS0gU2VsZWN0IGRhdGEgZnJvbSB0aGUgdGFyZ2V0IHRhYmxlIHRvIHZlcmlmeSBjaGFuZ2VzClNFTEVDVCAqIEZST00gZW1wbG95ZWVfdGFyZ2V0IE9SREVSIEJZIEVtcF9JRCwgc3RhcnRfZGF0ZQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: latest_employee_records; line 12 pos 5;\n'InsertIntoStatement 'UnresolvedRelation [employee_target], [], false, [Emp_ID, First_Name, Last_Name, Salary, Nationality, start_date, end_date, current_flag], false, false\n+- 'Project ['source.Emp_ID, 'source.First_Name, 'source.Last_Name, 'source.Salary, 'source.Nationality, 'source.timestamp, unresolvedalias(null, None), unresolvedalias(true, None)]\n   +- 'Filter ((NOT ('target.First_Name = 'source.First_Name) OR NOT ('target.Last_Name = 'source.Last_Name)) OR (NOT ('target.Salary = 'source.Salary) OR NOT ('target.Nationality = 'source.Nationality)))\n      +- 'Join Inner, (('target.Emp_ID = 'source.Emp_ID) AND ('target.end_date = 'source.timestamp))\n         :- 'SubqueryAlias source\n         :  +- 'UnresolvedRelation [latest_employee_records], [], false\n         +- SubqueryAlias target\n            +- SubqueryAlias spark_catalog.default.employee_target\n               +- Relation spark_catalog.default.employee_target[Emp_ID#6807,First_Name#6808,Last_Name#6809,Salary#6810,Nationality#6811,start_date#6812,end_date#6813,current_flag#6814] parquet\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: Table or view not found: latest_employee_records; line 12 pos 5;\n'InsertIntoStatement 'UnresolvedRelation [employee_target], [], false, [Emp_ID, First_Name, Last_Name, Salary, Nationality, start_date, end_date, current_flag], false, false\n+- 'Project ['source.Emp_ID, 'source.First_Name, 'source.Last_Name, 'source.Salary, 'source.Nationality, 'source.timestamp, unresolvedalias(null, None), unresolvedalias(true, None)]\n   +- 'Filter ((NOT ('target.First_Name = 'source.First_Name) OR NOT ('target.Last_Name = 'source.Last_Name)) OR (NOT ('target.Salary = 'source.Salary) OR NOT ('target.Nationality = 'source.Nationality)))\n      +- 'Join Inner, (('target.Emp_ID = 'source.Emp_ID) AND ('target.end_date = 'source.timestamp))\n         :- 'SubqueryAlias source\n         :  +- 'UnresolvedRelation [latest_employee_records], [], false\n         +- SubqueryAlias target\n            +- SubqueryAlias spark_catalog.default.employee_target\n               +- Relation spark_catalog.default.employee_target[Emp_ID#6807,First_Name#6808,Last_Name#6809,Salary#6810,Nationality#6811,start_date#6812,end_date#6813,current_flag#6814] parquet\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Create the source table if it does not exist, including the timestamp column\n",
    "CREATE TABLE IF NOT EXISTS employee_source (\n",
    "    Emp_ID INT,\n",
    "    First_Name STRING,\n",
    "    Last_Name STRING,\n",
    "    Salary FLOAT,\n",
    "    Nationality STRING,\n",
    "    timestamp TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Insert initial data into the source table\n",
    "INSERT INTO employee_source VALUES\n",
    "    (1, 'Scott', 'Tiger', 1000.0, 'India', CURRENT_TIMESTAMP()), \n",
    "    (2, 'John', 'Clair', 2000.0, 'UK', CURRENT_TIMESTAMP());\n",
    "\n",
    "-- Create the target table if it does not exist\n",
    "CREATE TABLE IF NOT EXISTS employee_target (\n",
    "    Emp_ID INT,\n",
    "    First_Name STRING,\n",
    "    Last_Name STRING,\n",
    "    Salary FLOAT,\n",
    "    Nationality STRING,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    current_flag BOOLEAN\n",
    ");\n",
    "\n",
    "-- Create a CTE to get the latest records from the source table\n",
    "WITH latest_employee_records AS (\n",
    "    SELECT Emp_ID, First_Name, Last_Name, Salary, Nationality, timestamp\n",
    "    FROM (\n",
    "        SELECT \n",
    "            *,\n",
    "            ROW_NUMBER() OVER (PARTITION BY Emp_ID ORDER BY timestamp DESC) as rn\n",
    "        FROM employee_source\n",
    "    ) subquery\n",
    "    WHERE rn = 1\n",
    ")\n",
    "\n",
    "-- Perform the SCD Type 2 MERGE operation\n",
    "MERGE INTO employee_target AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        Emp_ID, \n",
    "        First_Name, \n",
    "        Last_Name, \n",
    "        Salary, \n",
    "        Nationality, \n",
    "        timestamp\n",
    "    FROM latest_employee_records\n",
    ") AS source\n",
    "ON target.Emp_ID = source.Emp_ID AND target.current_flag = TRUE\n",
    "WHEN MATCHED \n",
    "    AND (\n",
    "        target.First_Name != source.First_Name OR \n",
    "        target.Last_Name != source.Last_Name OR \n",
    "        target.Salary != source.Salary OR \n",
    "        target.Nationality != source.Nationality\n",
    "    )\n",
    "THEN\n",
    "    UPDATE SET\n",
    "        target.current_flag = FALSE,\n",
    "        target.end_date = source.timestamp\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (\n",
    "        Emp_ID,\n",
    "        First_Name,\n",
    "        Last_Name,\n",
    "        Salary,\n",
    "        Nationality,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        current_flag\n",
    "    )\n",
    "    VALUES (\n",
    "        source.Emp_ID,\n",
    "        source.First_Name,\n",
    "        source.Last_Name,\n",
    "        source.Salary,\n",
    "        source.Nationality,\n",
    "        source.timestamp,\n",
    "        NULL,\n",
    "        TRUE\n",
    "    );\n",
    "\n",
    "-- Insert new records for the updated entries\n",
    "INSERT INTO employee_target (Emp_ID, First_Name, Last_Name, Salary, Nationality, start_date, end_date, current_flag)\n",
    "SELECT \n",
    "    source.Emp_ID, \n",
    "    source.First_Name, \n",
    "    source.Last_Name, \n",
    "    source.Salary, \n",
    "    source.Nationality, \n",
    "    source.timestamp,\n",
    "    NULL,\n",
    "    TRUE\n",
    "FROM latest_employee_records source\n",
    "JOIN employee_target target\n",
    "ON target.Emp_ID = source.Emp_ID AND target.end_date = source.timestamp\n",
    "WHERE target.First_Name != source.First_Name \n",
    "    OR target.Last_Name != source.Last_Name \n",
    "    OR target.Salary != source.Salary \n",
    "    OR target.Nationality != source.Nationality;\n",
    "\n",
    "-- Select data from the target table to verify changes\n",
    "SELECT * FROM employee_target ORDER BY Emp_ID, start_date;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "664c5a81-d07e-4db1-8e11-d1c8f4e5162d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Perform the SCD Type 2 MERGE operation\n",
    "MERGE INTO employee_target1 AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        Emp_ID, \n",
    "        First_Name, \n",
    "        Last_Name, \n",
    "        Salary, \n",
    "        Nationality, \n",
    "        timestamp\n",
    "    FROM latest_employee_records1\n",
    ") AS source\n",
    "ON target.Emp_ID = source.Emp_ID AND target.current_flag = TRUE\n",
    "WHEN MATCHED \n",
    "    AND (\n",
    "        target.First_Name != source.First_Name OR \n",
    "        target.Last_Name != source.Last_Name OR \n",
    "        target.Salary != source.Salary OR \n",
    "        target.Nationality != source.Nationality\n",
    "    )\n",
    "THEN\n",
    "    UPDATE SET\n",
    "        target.current_flag = FALSE,\n",
    "        target.end_date = source.timestamp\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (\n",
    "        Emp_ID,\n",
    "        First_Name,\n",
    "        Last_Name,\n",
    "        Salary,\n",
    "        Nationality,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        current_flag\n",
    "    )\n",
    "    VALUES (\n",
    "        source.Emp_ID,\n",
    "        source.First_Name,\n",
    "        source.Last_Name,\n",
    "        source.Salary,\n",
    "        source.Nationality,\n",
    "        source.timestamp,\n",
    "        NULL,\n",
    "        TRUE\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c313ac49-23db-449b-9f95-e827b26ece78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Insert new records for the updated entries\n",
    "INSERT INTO employee_target1 (Emp_ID, First_Name, Last_Name, Salary, Nationality, start_date, end_date, current_flag)\n",
    "SELECT \n",
    "    source.Emp_ID, \n",
    "    source.First_Name, \n",
    "    source.Last_Name, \n",
    "    source.Salary, \n",
    "    source.Nationality, \n",
    "    source.timestamp,\n",
    "    NULL,\n",
    "    TRUE\n",
    "FROM latest_employee_records1 source\n",
    "JOIN employee_target1 target\n",
    "ON target.Emp_ID = source.Emp_ID AND target.end_date = source.timestamp\n",
    "WHERE target.First_Name != source.First_Name \n",
    "    OR target.Last_Name != source.Last_Name \n",
    "    OR target.Salary != source.Salary \n",
    "    OR target.Nationality != source.Nationality;\n",
    "\n",
    "-- Select data from the target table to verify changes\n",
    "SELECT * FROM employee_target1 ORDER BY Emp_ID, start_date;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1101136203510778,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SCD Type 1 - PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
